{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "CORRECTION = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bRunAWS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_top_pixels = 55\n",
    "remove_bottom_pixels = 25\n",
    "WIDTH,HEIGHT,CHANNELS = 64,64,3\n",
    "\n",
    "# image resizing and cropping followed by normalization\n",
    "def preprocess_image(collection_images):\n",
    "\n",
    "    image = np.squeeze(collection_images[remove_top_pixels:-remove_bottom_pixels,:,:])\n",
    "    image = cv2.resize(image,(WIDTH,HEIGHT))\n",
    "    image = (image-128)/256\n",
    "            \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip image horizontally and steering angle to simulate right turns\n",
    "def flip_images(image, steering):\n",
    "\n",
    "    image_mod = cv2.flip(image,1)\n",
    "    steering_mod = steering*-1.0\n",
    "    \n",
    "    return (image_mod, steering_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random brightness to augment data and clip at 255\n",
    "def brightness_adjust(image, steering):\n",
    "    \n",
    "    image_mod = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    image_mod[:,:,2] = image_mod[:,:,2]*random_bright\n",
    "    image_mod[:,:,2][image_mod[:,:,2]>255] = 255\n",
    "    image_mod = cv2.cvtColor(image_mod,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    return (image_mod, steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data augmentation step involved\n",
    "1. Choosing either center, left or right image at random\n",
    "2. Flipping the image horizontally at random and multipling steering value with -1.0\n",
    "3. Multipling the image with random brightness to augment data\n",
    "4. Finally I preprocess the image by removing top and bottom pixels to remove irrelevant pixels and reducing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator for reading images\n",
    "def data_generator(data, batch_size):\n",
    "    \n",
    "    ii = 0\n",
    "    N = len(data)\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        start = ii*batch_size\n",
    "        end = np.amin(((ii+1)*batch_size,N))    \n",
    "        data_batches_files  = data[start:end]\n",
    "        center_image_files = np.asarray(data_batches_files['center'])\n",
    "        left_image_files = np.asarray(data_batches_files['left'])\n",
    "        right_image_files = np.asarray(data_batches_files['right'])\n",
    "        steering_arr = np.asarray(data_batches_files['steering'])\n",
    "\n",
    "        X_batches = np.zeros((batch_size, WIDTH, HEIGHT, CHANNELS), dtype=np.float32)\n",
    "        y_batches = np.zeros((batch_size,), dtype=np.float32)\n",
    "        \n",
    "        for kk in range(batch_size):\n",
    "        # Choose either of the image randomly\n",
    "            img_type = np.random.choice(['center','left','right'])\n",
    "            if(img_type=='center'):\n",
    "                image = plt.imread(path+center_image_files[kk])\n",
    "                steering = steering_arr[kk]\n",
    "            elif(img_type=='left'):    \n",
    "                image = plt.imread(path+left_image_files[kk][1:])\n",
    "                steering = steering_arr[kk]+CORRECTION\n",
    "            elif(img_type=='right'):\n",
    "                image = plt.imread(path+right_image_files[kk][1:])\n",
    "                steering = steering_arr[kk]-CORRECTION\n",
    "            \n",
    "            # choose the flipped image based on random distribution   \n",
    "            rand_num = np.random.random()\n",
    "            if rand_num>0.5:\n",
    "                image, steering = flip_images(image, steering)\n",
    "            #add random brightness to image\n",
    "            image, steering = brightness_adjust(image, steering)\n",
    "            X_batches[kk,:,:,:] = preprocess_image(image)\n",
    "            y_batches[kk] = steering\n",
    "        #increment counter but reset when all images have been iterated    \n",
    "        ii += 1\n",
    "        if ii>=(N//batch_size):\n",
    "            ii=0\n",
    "    \n",
    "        yield (X_batches, y_batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture -\n",
    "The model that worked was inspired by the NVIDIA SDC model, for some reason it didn't work for me. It deviated into the first lake on right. The subsequent modifications was able to work. \n",
    "\n",
    "1. convolution2d_1 (Convolution2D)\n",
    "2. elu_1 (ELU)\n",
    "3. convolution2d_2 (Convolution2D)\n",
    "4. elu_2 (ELU)\n",
    "5. dropout_1 (Dropout)\n",
    "6. maxpooling2d_1 (MaxPooling2D)\n",
    "7. convolution2d_3 (Convolution2D)\n",
    "8. elu_3 (ELU)\n",
    "9. dropout_2 (Dropout)\n",
    "10. convolution2d_4 (Convolution2D)\n",
    "11. elu_4 (ELU)\n",
    "12. dropout_3 (Dropout)\n",
    "13. flatten_1 (Flatten)\n",
    "14. dense_1 (Dense)\n",
    "15. dropout_4 (Dropout)\n",
    "16. dense_2 (Dense)\n",
    "17. dense_3 (Dense)\n",
    "18. dense_4 (Dense)\n",
    "\n",
    "Total params: 8,517,473\n",
    "Trainable params: 8,517,473\n",
    "Non-trainable params: 0\n",
    "________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, Cropping2D, Dropout, ELU\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "#nvidia SDC model as suggested in the exercise \n",
    "def nvidiaModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(24,5,5, input_shape=(WIDTH, HEIGHT, CHANNELS), subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "#modified version of nvidia adding dropouts for regularization, etc.\n",
    "def nvidiaModel_mod():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(24,8,8, input_shape=(WIDTH, HEIGHT, CHANNELS),subsample=(2,2)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(48,3,3, subsample=(1,1)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64,3,3))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64,3,3))\n",
    "    model.add(ELU())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Custom model based on trial and error and inspired from nvidia model itself\n",
    "def custom_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # layer 1 output shape is 32x32x32\n",
    "    model.add(Convolution2D(16, 5, 5, input_shape=(WIDTH, HEIGHT, CHANNELS), subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "\n",
    "    # layer 2 output shape is 15x15x16\n",
    "    model.add(Convolution2D(32, 3, 3, subsample=(1, 1), border_mode=\"valid\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(MaxPooling2D((2, 2), border_mode='valid'))\n",
    "\n",
    "    # layer 3 output shape is 12x12x16\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.4))\n",
    "\n",
    "    # layer 4 output shape is 12x12x16\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.4))\n",
    "    \n",
    "    # Flatten the output\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # layer 5\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(ELU())\n",
    "\n",
    "    # layer 6\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "\n",
    "    # Finally a single output, since this is a regression problem\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance data since majority are of 0 steering angle -> done to reduce bias of the model to drive straight\n",
    "def balance_data(df_log, zero_pct=0.5):\n",
    "    \n",
    "    total_data_size = len(df_log)\n",
    "    steering_arr = np.asarray(df_log['steering'])\n",
    "    zero_idx = []  \n",
    "    for ii in range(total_data_size):\n",
    "        if np.absolute(steering_arr[[ii]]) <= 0.25:\n",
    "            zero_idx.append(ii)\n",
    "\n",
    "    nonzero_data_size = total_data_size - len(zero_idx)\n",
    "    zero_data_size = int(zero_pct * nonzero_data_size / (1 - zero_pct))\n",
    "\n",
    "    remove_idx = np.random.choice(zero_idx, total_data_size - zero_data_size - nonzero_data_size, replace=False)\n",
    "    df_log = df_log.drop(df_log.index[remove_idx]) \n",
    "    \n",
    "    return df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training strategy\n",
    "The training strategy was to start from the NVIDIA model architecture and tweak all its hyperparameters, i.e. batch-size, data_size, epochs\n",
    "This led to straight-forward improvements of adding regularization such as drop-out, tried L2 regularization but didnot help.\n",
    "Used the intuition of gradually complex or deep but shrinking width, height kernels from earlier lecture to refine the Nvidia model. The model seems to work well however it deviates off the track after the bridge where one side of the road isnot present. To circumvent this issue tried adding the balancing data feature of dropping images with abs(steering_angle) less than 0.25. But this too didnot help. Would like to add more data/image but driving along the track, however could not even after 10-12 tries. Controlling the car in training mode is quite difficult hence had to rely completely on the images provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    #Select path according to where its run\n",
    "    if bRunAWS==1:\n",
    "        path = 'examples/data/'\n",
    "    else:\n",
    "        path = 'C:/Users/AVIK/Documents/Udacity Self Driving Cars/CarND-Behavioral-Cloning-P3-master/examples/data/'\n",
    "    \n",
    "    # read the .xls file\n",
    "    df_log = pd.read_csv(path+\"driving_log.csv\")\n",
    "    \n",
    "    #drop near zero steering angle images to remove bias(added later but didn't help) \n",
    "    df_log = balance_data(df_log, zero_pct=0.5)\n",
    "    \n",
    "    center_image,left_image,right_image, steering = df_log['center'],df_log['left'],df_log['right'], df_log['steering']\n",
    "    \n",
    "    #shuffle data\n",
    "    df_log = df_log.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    training_split = 0.8\n",
    "    #split training and validation data after random shuffle or dataframe rows\n",
    "    training_data_rows = df_log.loc[0:int(len(df_log)*training_split)]    \n",
    "    validation_data_rows = df_log.loc[int(len(df_log)*training_split):]\n",
    "    \n",
    "    #adding the training/validation generator functions\n",
    "    training_generator = data_generator(training_data_rows, batch_size=BATCH_SIZE)\n",
    "    validation_data_generator = data_generator(validation_data_rows, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = custom_model()\n",
    "    model.summary()\n",
    "\n",
    "    # Compile model with Adam optimizer with learning rate as hyper-parameter. Tried - 0.0001(works best), 0.0005, 0.0008\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "    \n",
    "    #determines number of images/samples to iterate over during training\n",
    "    samples_per_epoch = (len(training_data_rows)*30//BATCH_SIZE)*BATCH_SIZE \n",
    "    \n",
    "    # fit.generator to train/validate the model\n",
    "    history_object = model.fit_generator(training_generator, validation_data=validation_data_generator,\n",
    "                        samples_per_epoch=samples_per_epoch, nb_epoch=3, nb_val_samples=len(validation_data_rows)*15)\n",
    "\n",
    "    print(\"Saving model weights and configuration file.\")\n",
    "\n",
    "    model.save('model.h5')  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
